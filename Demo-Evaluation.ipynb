{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import pyewts\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from evaluate import load\n",
    "from natsort import natsorted\n",
    "from Modules import Easter2Inference, TrOCRInference, CRNNInference\n",
    "from huggingface_hub import snapshot_download\n",
    "from Utils import get_filename, read_ctc_model_config, read_label, show_image, preprare_ocr_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# set up wylie converter and the CER scorer\n",
    "converter = pyewts.pyewts()\n",
    "cer_scorer = load(\"cer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup data\n",
    "data_path = snapshot_download(repo_id=\"BDRC/KhyentseWangpo\", repo_type=\"dataset\",  cache_dir=\"Datasets\")\n",
    "\n",
    "lines = natsorted(glob(f\"{data_path}/lines/*.jpg\"))\n",
    "labels = natsorted(glob(f\"{data_path}/transcriptions/*.txt\"))\n",
    "\n",
    "print(f\"Images: {len(lines)}, Labels: {len(labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a sample from the dataset\n",
    "idx = random.randint(0, len(lines)-1)\n",
    "img = cv2.imread(lines[idx])\n",
    "show_image(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring unsing CRNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download a model: https://huggingface.co/BDRC/GoogleBooks_C_v1\n",
    "model_id = \"BDRC/GoogleBooks_C_v1\"\n",
    "model_path = snapshot_download(\n",
    "                repo_id=model_id,\n",
    "                repo_type=\"model\",\n",
    "                local_dir=f\"Models/{model_id}\",\n",
    "            )\n",
    "\n",
    "print(model_path)\n",
    "model_config = f\"{model_path}/config.json\"\n",
    "\n",
    "assert(os.path.isfile(model_config))\n",
    "\n",
    "ocr_config = read_ctc_model_config(model_config)\n",
    "crnn_inference = CRNNInference(ocr_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crnn_scores = {}\n",
    "\n",
    "for image_path, label_path in tqdm(zip(lines, labels), total=len(lines)):\n",
    "    image_n = get_filename(image_path)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    gt_lbl = read_label(label_path)\n",
    "    gt_lbl = converter.toWylie(gt_lbl)\n",
    "    prediction = crnn_inference.predict(image)\n",
    "\n",
    "    try:\n",
    "        if prediction != \"\" and gt_lbl != \"\":\n",
    "            cer_score = cer_scorer.compute(predictions=[prediction], references=[gt_lbl])\n",
    "            crnn_scores[image_n] = cer_score\n",
    "    except BaseException as e:\n",
    "        print(f\"Failed to calculate CER for prediction: {prediction} against labek: {gt_lbl}, raised exception: {e}\")\n",
    "\n",
    "\n",
    "cer_values = list(crnn_scores.values())\n",
    "mean_cer = np.mean(cer_values)\n",
    "max_cer = np.max(cer_values)\n",
    "min_cer = np.min(cer_values)\n",
    "print(f\"Mean CER: {mean_cer}, Max CER: {max_cer}, Min CER: {min_cer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring using Easter2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the model: https://huggingface.co/BDRC/GoogleBooks_E_v1\n",
    "model_id = \"BDRC/GoogleBooks_E_v1\"\n",
    "model_path = snapshot_download(\n",
    "                repo_id=model_id,\n",
    "                repo_type=\"model\",\n",
    "                local_dir=f\"Models/{model_id}\",\n",
    "            )\n",
    "\n",
    "print(model_path)\n",
    "model_config = f\"{model_path}/config.json\"\n",
    "\n",
    "assert(os.path.isfile(model_config))\n",
    "\n",
    "ocr_config = read_ctc_model_config(model_config)\n",
    "easter2_inference = Easter2Inference(ocr_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "easter_cer_scores = {}\n",
    "\n",
    "for image_path, label_path in tqdm(zip(lines, labels), total=len(lines)):\n",
    "    image_n = get_filename(image_path)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    gt_lbl = read_label(label_path)\n",
    "    gt_lbl = converter.toWylie(gt_lbl)\n",
    "    prediction = easter2_inference.predict(image)\n",
    "\n",
    "    try:\n",
    "        if prediction != \"\" and gt_lbl != \"\":\n",
    "            cer_score = cer_scorer.compute(predictions=[prediction], references=[gt_lbl])\n",
    "            easter_cer_scores[image_n] = cer_score\n",
    "    except BaseException as e:\n",
    "        print(f\"Failed to calculate CER for prediction: {prediction} against labek: {gt_lbl}, raised exception: {e}\")\n",
    "\n",
    "\n",
    "cer_values = list(easter_cer_scores.values())\n",
    "mean_cer = np.mean(cer_values)\n",
    "max_cer = np.max(cer_values)\n",
    "min_cer = np.min(cer_values)\n",
    "print(f\"Mean CER: {mean_cer}, Max CER: {max_cer}, Min CER: {min_cer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring using TrOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the model: https://huggingface.co/BDRC/GoogleBooks_T_v1\n",
    "\n",
    "model_id = \"BDRC/GoogleBooks_T_v1\"\n",
    "checkpoint = snapshot_download(\n",
    "                repo_id=model_id,\n",
    "                repo_type=\"model\",\n",
    "                local_dir=f\"Models/{model_id}\",\n",
    "            )\n",
    "trocr_inference = TrOCRInference(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trocr_scores = {}\n",
    "\n",
    "for image_path, label_path in tqdm(zip(lines, labels), total=len(lines)):\n",
    "    image_n = get_filename(image_path)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    gt_lbl = read_label(label_path)\n",
    "    prediction = trocr_inference.predict(image)\n",
    "\n",
    "    try:\n",
    "        if prediction != \"\" and gt_lbl != \"\":\n",
    "            cer_score = cer_scorer.compute(predictions=[prediction], references=[gt_lbl])\n",
    "            trocr_scores[image_n] = cer_score\n",
    "    except BaseException as e:\n",
    "        print(f\"Failed to calculate CER for prediction: {prediction} against labek: {gt_lbl}, raised exception: {e}\")\n",
    "\n",
    "\n",
    "cer_values = list(trocr_scores.values())\n",
    "mean_cer = np.mean(cer_values)\n",
    "max_cer = np.max(cer_values)\n",
    "min_cer = np.min(cer_values)\n",
    "print(f\"Mean CER: {mean_cer}, Max CER: {max_cer}, Min CER: {min_cer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
